{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee54d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 717, which is longer than the specified 600\n",
      "Created a chunk of size 608, which is longer than the specified 600\n",
      "Created a chunk of size 642, which is longer than the specified 600\n",
      "Created a chunk of size 1444, which is longer than the specified 600\n",
      "Created a chunk of size 1251, which is longer than the specified 600\n",
      "Created a chunk of size 1012, which is longer than the specified 600\n",
      "Created a chunk of size 1493, which is longer than the specified 600\n",
      "Created a chunk of size 819, which is longer than the specified 600\n",
      "Created a chunk of size 1458, which is longer than the specified 600\n",
      "Created a chunk of size 1411, which is longer than the specified 600\n",
      "Created a chunk of size 742, which is longer than the specified 600\n",
      "Created a chunk of size 669, which is longer than the specified 600\n",
      "Created a chunk of size 906, which is longer than the specified 600\n",
      "Created a chunk of size 703, which is longer than the specified 600\n",
      "Created a chunk of size 1137, which is longer than the specified 600\n",
      "Created a chunk of size 1417, which is longer than the specified 600\n",
      "Created a chunk of size 1200, which is longer than the specified 600\n",
      "Created a chunk of size 859, which is longer than the specified 600\n",
      "Created a chunk of size 845, which is longer than the specified 600\n",
      "Created a chunk of size 716, which is longer than the specified 600\n",
      "Created a chunk of size 840, which is longer than the specified 600\n",
      "Created a chunk of size 1042, which is longer than the specified 600\n",
      "Created a chunk of size 652, which is longer than the specified 600\n",
      "Created a chunk of size 985, which is longer than the specified 600\n",
      "Created a chunk of size 859, which is longer than the specified 600\n",
      "Created a chunk of size 659, which is longer than the specified 600\n",
      "Created a chunk of size 693, which is longer than the specified 600\n",
      "Created a chunk of size 817, which is longer than the specified 600\n",
      "Created a chunk of size 655, which is longer than the specified 600\n",
      "Created a chunk of size 1345, which is longer than the specified 600\n",
      "Created a chunk of size 1339, which is longer than the specified 600\n",
      "Created a chunk of size 1288, which is longer than the specified 600\n",
      "Created a chunk of size 1014, which is longer than the specified 600\n",
      "Created a chunk of size 617, which is longer than the specified 600\n",
      "Created a chunk of size 617, which is longer than the specified 600\n",
      "Created a chunk of size 1178, which is longer than the specified 600\n",
      "Created a chunk of size 1444, which is longer than the specified 600\n",
      "Created a chunk of size 802, which is longer than the specified 600\n",
      "Created a chunk of size 1496, which is longer than the specified 600\n",
      "Created a chunk of size 841, which is longer than the specified 600\n",
      "Created a chunk of size 743, which is longer than the specified 600\n",
      "Created a chunk of size 694, which is longer than the specified 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with, but the narrator had never seen the photograph that disproved their guilt and believed it had never existed."
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature =0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\",\n",
    "    return_messages=False\n",
    ")\n",
    "\n",
    "#문서 splitter와 loader\n",
    "splitter= CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_three.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "#로딩할 문서 cache 및 embedding\n",
    "\n",
    "cache_dir = LocalFileStore(\"./cache/\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cache_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "#검색할 도구 생성(vectorstore and retriever)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cache_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "#prompt 생성: 잘 모르겠는 답은 이야기하지 마라.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful assistance. Answer question using only following text. \"\n",
    "     \"If you don't know the answer just say you don't know, don't make it up:\\n\\n\"\n",
    "     \"Context:\\n{context}\\n\\n\"\n",
    "     \"Conversation so far:\\n{history}\"\n",
    "    ),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "def load_memory(input):\n",
    "    return memory.load_memory_variables({})[\"history\"] \n",
    "\n",
    "#docs를 문자로 바꿈. 배열의 content를 가지고 와서 하나의 문서로 엮음.\n",
    "def doc_to_str(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "#retriever에 doc_to_str을 추가시켜 줌. history는 함수가 실행되는 것이므로 그대로 \n",
    "# question이 retriever로 넘어갈때 dic구조 그대로 넘어가서 생기는 문제라고 함.\n",
    "chain = { \"context\":itemgetter(\"question\")|retriever | doc_to_str, \"history\":load_memory, \"question\":itemgetter(\"question\")} | prompt | llm\n",
    "\n",
    "#대화 내용을 저장하는 로직 만들기\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"question\":question\n",
    "        }\n",
    "        )\n",
    "    memory.save_context({\"input\":question},{\"output\":result.content}) \n",
    "\n",
    "invoke_chain(\"Is Aaronson guilty?\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cfa8d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He wrote: FREEDOM IS SLAVERY, TWO AND TWO MAKE FIVE, and GOD IS POWER."
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What message did he write on the table?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "948711de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia is a character who is loved by the narrator. She is mentioned in the context of the narrator's overwhelming feelings for her and his desire to help her."
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Who is Julia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833f801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
